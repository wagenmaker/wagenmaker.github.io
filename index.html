<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc2.css" type="text/css" />
<title>Andrew Wagenmaker</title>
<style>
    .hidepaper {
        display: none;
    }
    .content-section {
        display: flex;
        align-items: flex-start;
        margin-bottom: 20px;
    }
    .content-section img {
        margin-right: 20px;
    }
    .content-section p {
        margin: 0;
    }
    .image-caption {
        text-align: center;
        margin-top: 15px !important; 
    }
</style>
<style>
img {
    float: left;
    margin-right: 20px;
    margin-bottom: 15px;
}
</style>
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>Andrew Wagenmaker</h1>
</div>
<br />

<img src="andrew.jpg" alt="Test" width="240"> 


<p>I am a postdoctoral researcher in Electrical Engineering and Computer Science at UC Berkeley working with <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a>. Previously, I completed a PhD in Computer Science at the University of Washington, where I was advised by <a href="https://homes.cs.washington.edu/~jamieson/about.html">Kevin Jamieson</a>. While in graduate school, I also spent time at Microsoft Research, mentored by <a href="https://dylanfoster.net">Dylan Foster</a>, as well as the Simons Institute, and my work was supported by an NSF Graduate Research Fellowship. Before that, I completed a master's and bachelor's degree at the University of Michigan, both in Electrical Engineering.
 </p>


<p>My research centers on developing learning-based algorithms for decision-making in sequential environments, both in theory and practice, and has spanned settings such as multi-armed bandits, reinforcement learning, and continuous control. In particular, much of my work has focused on developing algorithms which go beyond the worst case and provably adapt to the difficulty of, and perform optimally on, each <i>particular</i> problem instance.</p>



<p>Obtaining such <i>instance-optimal</i> guarantees often necessitates novel algorithmic techniques, especially in developing methods that effectively <i>explore</i>: efficiently collecting information about a given environment in order to learn to accomplish a desired goal. As such, a primary focus of my work has been in designing novel algorithmic approaches to exploration in dynamic environments. At present, I am primarily interested in developing effective approaches to real-world decision-making problems. 
</p>


 <p style="text-align: center;"><a href="mailto:ajwagen@berkeley.edu">Mail</a> / <a href="https://scholar.google.com/citations?user=ym8AZSIAAAAJ&hl=en&oi=ao">Google Scholar</a></p>




<h2 id="toggle">Selected Publications (<a onclick="toggleText()">Show All</a>):</h2>


<p><a href="https://arxiv.org/pdf/2410.20254">Overcoming the Sim-to-Real Gap: Leveraging Simulation to Learn to Explore for Real-World RL</a> 
<br><b>Andrew Wagenmaker</b>, Kevin Huang, Liyiming Ke, Byron Boots, Kevin Jamieson, and Abhishek Gupta
<br><i>NeurIPS</i>, 2024</p>


<p class="hidepaper"><a href="https://arxiv.org/pdf/2406.06856">Sample Complexity Reduction via Policy Difference Estimation in Tabular Reinforcement Learning</a> 
<br>Adhyyan Narang, <b>Andrew Wagenmaker</b>, Lillian Ratliff, and Kevin Jamieson
<br><i>NeurIPS</i>, 2024 (Spotlight)</p>


<p class="hidepaper"><a href="https://arxiv.org/pdf/2406.10522">Humor in AI: Massive Scale Crowd-Sourced Preferences and Benchmarks for Cartoon Captioning</a> 
<br>Jifan Zhang, Lalit Jain, Yang Guo, Jiayi Chen, Kuan Lok Zhou, Siddharth Suresh, <b>Andrew Wagenmaker</b>, Scott Sievert, Timothy Rogers, Kevin Jamieson, Robert Mankoff, and Robert Nowak
<br><i>NeurIPS</i>, 2024 (Datasets & Benchmarks Track, Spotlight)</p>


<p class="hidepaper"><a href="https://arxiv.org/pdf/2410.07533">Corruption-Robust Linear Bandits: Minimax Optimality and Gap-Dependent Misspecification</a> 
<br>Haolin Liu, Artin Tajdini, <b>Andrew Wagenmaker</b>, and Chen-Yu Wei
<br><i>NeurIPS</i>, 2024</p>


<p class="hidepaper"><a href="https://arxiv.org/pdf/2312.08559.pdf">Fair Active Learning in Low-Data Regimes</a> 
<br>Romain Camilleri, <b>Andrew Wagenmaker</b>, Jamie Morgenstern, Lalit Jain, and Kevin Jamieson
<br><i>UAI</i>, 2024</p>

<p class="hidepaper"><a href="https://weirdlabuw.github.io/asid/">ASID: Active Exploration for System Identification in Robotic Manipulation</a> 
<br>Marius Memmel, <b>Andrew Wagenmaker</b>, Chuning Zhu, Patrick Yin, Dieter Fox, and Abhishek Gupta
<br><i>ICLR</i>, 2024 (Oral)</p>


<p class="hidepaper"><a href="https://arxiv.org/pdf/2306.09210.pdf">Optimal Exploration for Model-Based RL in Nonlinear Systems</a> 
<br><b>Andrew Wagenmaker</b>, Guanya Shi, and Kevin Jamieson
<br><i>NeurIPS</i>, 2023 (Spotlight) [<a href="https://github.com/ajwagen/nonlinear_sysid_for_control">Code</a>]</p>

<p><a href="https://arxiv.org/pdf/2304.12466.pdf">Instance-Optimality in Interactive Decision Making: Toward a Non-Asymptotic Theory</a> 
<br><b>Andrew Wagenmaker</b> and Dylan Foster
<br><i>COLT</i>, 2023 [<a href="https://www.youtube.com/watch?v=Aly2Pnc7kpM">Talk</a>]</p>

<p><a href="https://arxiv.org/pdf/2211.04974.pdf">Leveraging Offline Data in Online Reinforcement Learning</a> 
<br><b>Andrew Wagenmaker</b> and Aldo Pacchiano
<br><i>ICML</i>, 2023 [<a href="https://www.youtube.com/watch?v=OkkcO9uL4hM">Talk</a>]</p>

<p class="hidepaper"><a href="https://arxiv.org/pdf/2207.02575.pdf">Instance-Dependent Near-Optimal Policy Identification in Linear MDPs via Online Experiment Design</a> 
<br><b>Andrew Wagenmaker</b> and Kevin Jamieson
<br><i>NeurIPS</i>, 2022</p>

<p class="hidepaper"><a href="https://arxiv.org/pdf/2206.11183.pdf">Active Learning with Safety Constraints</a> 
<br>Romain Camilleri, <b>Andrew Wagenmaker</b>, Jamie Morgenstern, Lalit Jain, and Kevin Jamieson
<br><i>NeurIPS</i>, 2022</p>

<p><a href="https://arxiv.org/pdf/2201.11206.pdf">Reward-Free RL is No Harder Than Reward-Aware RL in Linear Markov Decision Processes</a> 
<br><b>Andrew Wagenmaker</b>, Yifang Chen, Max Simchowitz, Simon S. Du, and Kevin Jamieson
<br><i>ICML</i>, 2022</p>

<p><a href="https://arxiv.org/pdf/2112.03432.pdf">First-Order Regret in Reinforcement Learning with Linear Function
Approximation: A Robust Estimation Approach</a>
<br><b>Andrew Wagenmaker</b>, Yifang Chen, Max Simchowitz, Simon S. Du, and Kevin Jamieson
<br><i>ICML</i>, 2022 (Long Talk) [<a href="https://www.youtube.com/watch?v=_4gIfZYkIGw">Talk</a>]</p>


<p><a href="https://arxiv.org/pdf/2108.02717.pdf">Beyond No Regret: Instance-Dependent PAC Reinforcement Learning</a> 
<br><b>Andrew Wagenmaker</b>, Max Simchowitz, and Kevin Jamieson
<br><i>COLT</i>, 2022 [<a href="https://www.youtube.com/watch?v=8faG79P_QAA">Talk</a>]</p>

<p class="hidepaper"><a href="https://arxiv.org/pdf/2111.12151.pdf">Best Arm Identification with Safety Constraints</a> 
<br>Zhenlin Wang, <b>Andrew Wagenmaker</b>, and Kevin Jamieson
<br><i>AISTATS</i>, 2022</p>

<p><a href="https://arxiv.org/pdf/2102.05214.pdf">Task-Optimal Exploration in Linear Dynamical Systems</a>   
<br><b>Andrew Wagenmaker</b>, Max Simchowitz, and Kevin Jamieson
<br><i>ICML</i>, 2021 (Long Talk)</p>

<p class="hidepaper"><a href="https://arxiv.org/pdf/2011.00576.pdf">Experimental Design for Regret Minimization in Linear Bandits</a>  
<br><b>Andrew Wagenmaker</b>*, Julian Katz-Samuels*, and Kevin Jamieson
<br><i>AISTATS</i>, 2021</p>

<p class="hidepaper"><a href="https://arxiv.org/pdf/2002.00495.pdf">Active Learning for Identification of Linear Dynamical Systems</a>  
<br><b>Andrew Wagenmaker</b> and Kevin Jamieson
<br><i>COLT</i>, 2020 [<a href="https://www.youtube.com/watch?v=vs6zi93upfM">Talk</a>]</p>


<p class="hidepaper"><a href="https://arxiv.org/pdf/1710.08873.pdf">Robust Photometric Stereo via Dictionary Learning</a>
<br><b>Andrew Wagenmaker</b>, Brian Moore, and Raj Rao Nadakuditi
<br> <i>IEEE Transactions on Computational Imaging</i>, 2018</p>


<p class="hidepaper"><a href="https://arxiv.org/pdf/1710.00002.pdf">Robust Photometric Stereo Using Learned Image and Gradient Dictionaries</a>
<br><b>Andrew Wagenmaker</b>, Brian Moore, and Raj Rao NadakuditiÂ 
<br><i>ICIP</i>, 2017</p>


<p class="hidepaper"><a href="https://arxiv.org/pdf/1710.00230.pdf">Robust Surface Reconstruction from Gradients via Adaptive Dictionary Regularization</a>
<br><b>Andrew Wagenmaker</b>, Brian Moore, and Raj Rao Nadakuditi
<br><i>ICIP</i>, 2017</p>


<p class="hidepaper"><a href="https://web.eecs.umich.edu/~necmiye/pubs/WagenmakerO_allerton16.pdf">A Bisimulation-Like Algorithm for Abstracting Control Systems</a>
<br><b>Andrew Wagenmaker</b> and Necmiye Ozay
<br><i>Allerton</i>, 2016</p>




<!-- <h2 class="hidepaper">Preprints</h2> -->





<script>
  function toggleText() {
    const texts = document.querySelectorAll(".hidepaper");
    
    texts.forEach(text => {
      const currentDisplay = window.getComputedStyle(text).display;
      const button = document.getElementById("toggle");        

      if (currentDisplay === "none") {
        text.style.display = "block";
        button.innerHTML = 'All Publications (<a onclick="toggleText()">Show Selected Only</a>):';
      } else {
        text.style.display = "none";
        button.innerHTML = 'Selected Publications (<a onclick="toggleText()">Show All</a>):';
      }
    });
  }
</script>

</div>

<br>



</div>
</body>
</html>
