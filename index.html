<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="style.css" type="text/css" />
<title>Andrew Wagenmaker</title>
</head>
<body>
<div id="layout-content">

<div class="hero">
  <div class="hero-text">
    <div id="toptitle">
      <h1>Andrew Wagenmaker</h1>
    </div>
    <p class="contact">
      <span class="position">Postdoctoral Scholar</span> <br>
      <span class="position">Electrical Engineering & Computer Science</span> <br>
      <span class="position">UC Berkeley</span><br>
      <br>
      <span class="email">ajwagen AT berkeley DOT edu</span><br>
      <a class="twitter" href="https://x.com/ajwagenmaker" target="_blank" rel="me noopener">Twitter</a> /
      <a class="scholar" href="https://scholar.google.com/citations?user=ym8AZSIAAAAJ&hl=en&oi=ao">Scholar</a>
    </p>
  </div>
  <img src="andrew2.jpg" alt="Andrew Wagenmaker" class="hero-photo" />
</div>

<p>
  I am a postdoc in EECS at UC Berkeley working with <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a>. Previously, 
  I completed a PhD in Computer Science at the University of Washington, where I was advised by <a href="https://homes.cs.washington.edu/~jamieson/about.html">Kevin Jamieson</a>. 
  While in graduate school, I also spent time at Microsoft Research, mentored by <a href="https://dylanfoster.net">Dylan Foster</a>, as well as the Simons Institute, 
  and my work was supported by an NSF Graduate Research Fellowship. Before that, I completed a master's and bachelor's degree at the University of Michigan, both in Electrical Engineering.
 </p>

<p>
My research focuses on learning in dynamic, sequential, and interactive settings, and spans the spectrum from fundamental theory to practical algorithms for real-world decision-making. In particular, much of my work focuses on developing 
effective and scalable approaches to <i>exploration</i>, with the goal of enabling efficient <i>online policy improvement</i>. That is, how should we attempt novel behaviors during online deployment in order to identify better
solution strategies than those currently known, and how can we use the experience collected from this process to improve our performance over time?
</p>

<p>
  I seek to develop a fundamental theoretical understanding of such questions, and to apply these theoretical insights
  to motivate novel algorithmic techniques that lead to real-world impact, particularly towards enabling fast and efficient learning in robotic control settings.
</p>


<p style="text-align: center;"><b>I am on the 2025-2026 academic job market.</b></p>




<h2 id="toggle">Selected Publications (<a onclick="toggleText()">Show All</a>):</h2>

<p><a href="https://arxiv.org/pdf/2512.16911">Posterior Behavioral Cloning: Pretraining BC Policies for Efficient RL Finetuning</a>
<br><b>Andrew Wagenmaker</b>, Perry Dong, Raymond Tsao, Chelsea Finn, and Sergey Levine
<br><i>In Submission</i>, 2025</p>

<p class="hidepaper"><a href="https://arxiv.org/pdf/2512.08333">Robust Finetuning of Vision-Language-Action Robot Policies via Parameter Merging</a>
<br>Yajat Yadav<sup>c</sup>, Zhiyuan Zhou<sup>c</sup>, <b>Andrew Wagenmaker</b>, Karl Pertsch, and Sergey Levine
<br><i>In Submission</i>, 2025</p>
  
<p><a href="https://arxiv.org/pdf/2506.15799">Steering Your Diffusion Policy with Latent Space Reinforcement Learning</a> 
<br><b>Andrew Wagenmaker</b><sup>c</sup>, Mitsuhiko Nakamoto<sup>c</sup>, Yunchu Zhang<sup>c</sup>, Seohong Park, Waleed Yagoub, Anusha Nagabandi, Abhishek Gupta<sup>c</sup>, and Sergey Levine<sup>c</sup>
<br><i>CoRL</i>, 2025 (<span class="oral">Oral</span>, <span class="award">Best Paper Award Nomination</span>) [<a href="https://diffusion-steering.github.io">Website</a>] [<a href="https://github.com/ajwagen/dsrl">Code</a>]</p>

<p><a href="https://arxiv.org/pdf/2507.09041">Behavioral Exploration: Learning to Explore via In-Context Adaptation</a> 
<br><b>Andrew Wagenmaker</b>, Zhiyuan Zhou, and Sergey Levine
<br><i>ICML</i>, 2025</p>

<p><a href="https://arxiv.org/pdf/2410.20254">Overcoming the Sim-to-Real Gap: Leveraging Simulation to Learn to Explore for Real-World RL</a> 
<br><b>Andrew Wagenmaker</b>, Kevin Huang, Liyiming Ke, Byron Boots, Kevin Jamieson, and Abhishek Gupta
<br><i>NeurIPS</i>, 2024</p>

<p class="hidepaper"><a href="https://arxiv.org/pdf/2412.02529">Active Learning of Neural Population Dynamics Using Two-Photon Holographic Optogenetics</a> 
<br><b>Andrew Wagenmaker</b>*, Lu Mi*, Marton Rozsa, Matthew S. Bull, Karel Svoboda, Kayvon Daie<sup>&dagger;</sup>, Matthew D. Golub<sup>&dagger;</sup>, and Kevin Jamieson<sup>&dagger;</sup> 
<br><i>NeurIPS</i>, 2024</p>

<p class="hidepaper"><a href="https://arxiv.org/pdf/2406.06856">Sample Complexity Reduction via Policy Difference Estimation in Tabular Reinforcement Learning</a> 
<br>Adhyyan Narang, <b>Andrew Wagenmaker</b>, Lillian Ratliff, and Kevin Jamieson
<br><i>NeurIPS</i>, 2024 (<span class="oral">Spotlight</span>)</p>

<p class="hidepaper"><a href="https://arxiv.org/pdf/2406.10522">Humor in AI: Massive Scale Crowd-Sourced Preferences and Benchmarks for Cartoon Captioning</a> 
<br>Jifan Zhang, Lalit Jain, Yang Guo, Jiayi Chen, Kuan Lok Zhou, Siddharth Suresh, <b>Andrew Wagenmaker</b>, Scott Sievert, Timothy Rogers, Kevin Jamieson, Robert Mankoff, and Robert Nowak
<br><i>NeurIPS</i>, 2024 (Datasets & Benchmarks Track, <span class="oral">Spotlight</span>)</p>

<p class="hidepaper"><a href="https://arxiv.org/pdf/2410.07533">Corruption-Robust Linear Bandits: Minimax Optimality and Gap-Dependent Misspecification</a> 
<br>Haolin Liu<sup>&alpha;</sup>, Artin Tajdini<sup>&alpha;</sup>, <b>Andrew Wagenmaker</b><sup>&alpha;</sup>, and Chen-Yu Wei<sup>&alpha;</sup>
<br><i>NeurIPS</i>, 2024</p>

<p class="hidepaper"><a href="https://arxiv.org/pdf/2312.08559.pdf">Fair Active Learning in Low-Data Regimes</a> 
<br>Romain Camilleri, <b>Andrew Wagenmaker</b>, Jamie Morgenstern, Lalit Jain, and Kevin Jamieson
<br><i>UAI</i>, 2024</p>

<p class="hidepaper"><a href="https://weirdlabuw.github.io/asid/">ASID: Active Exploration for System Identification in Robotic Manipulation</a> 
<br>Marius Memmel, <b>Andrew Wagenmaker</b>, Chuning Zhu, Patrick Yin, Dieter Fox, and Abhishek Gupta
<br><i>ICLR</i>, 2024 (<span class="oral">Oral</span>)</p>

<p class="hidepaper"><a href="https://arxiv.org/pdf/2306.09210.pdf">Optimal Exploration for Model-Based RL in Nonlinear Systems</a> 
<br><b>Andrew Wagenmaker</b>, Guanya Shi, and Kevin Jamieson
<br><i>NeurIPS</i>, 2023 (<span class="oral">Spotlight</span>) [<a href="https://github.com/ajwagen/nonlinear_sysid_for_control">Code</a>]</p>

<p><a href="https://arxiv.org/pdf/2304.12466.pdf">Instance-Optimality in Interactive Decision Making: Toward a Non-Asymptotic Theory</a> 
<br><b>Andrew Wagenmaker</b> and Dylan Foster
<br><i>COLT</i>, 2023 [<a href="https://www.youtube.com/watch?v=Aly2Pnc7kpM">Talk</a>]</p>

<p><a href="https://arxiv.org/pdf/2211.04974.pdf">Leveraging Offline Data in Online Reinforcement Learning</a> 
<br><b>Andrew Wagenmaker</b> and Aldo Pacchiano
<br><i>ICML</i>, 2023 [<a href="https://www.youtube.com/watch?v=OkkcO9uL4hM">Talk</a>]</p>

<p class="hidepaper"><a href="https://arxiv.org/pdf/2207.02575.pdf">Instance-Dependent Near-Optimal Policy Identification in Linear MDPs via Online Experiment Design</a> 
<br><b>Andrew Wagenmaker</b> and Kevin Jamieson
<br><i>NeurIPS</i>, 2022</p>

<p class="hidepaper"><a href="https://arxiv.org/pdf/2206.11183.pdf">Active Learning with Safety Constraints</a> 
<br>Romain Camilleri, <b>Andrew Wagenmaker</b>, Jamie Morgenstern, Lalit Jain, and Kevin Jamieson
<br><i>NeurIPS</i>, 2022</p>

<p><a href="https://arxiv.org/pdf/2201.11206.pdf">Reward-Free RL is No Harder Than Reward-Aware RL in Linear Markov Decision Processes</a> 
<br><b>Andrew Wagenmaker</b>, Yifang Chen, Max Simchowitz, Simon S. Du, and Kevin Jamieson
<br><i>ICML</i>, 2022</p>

<p><a href="https://arxiv.org/pdf/2112.03432.pdf">First-Order Regret in Reinforcement Learning with Linear Function
Approximation: A Robust Estimation Approach</a>
<br><b>Andrew Wagenmaker</b>, Yifang Chen, Max Simchowitz, Simon S. Du, and Kevin Jamieson
<br><i>ICML</i>, 2022 (<span class="oral">Long Talk</span>) [<a href="https://www.youtube.com/watch?v=_4gIfZYkIGw">Talk</a>]</p>

<p><a href="https://arxiv.org/pdf/2108.02717.pdf">Beyond No Regret: Instance-Dependent PAC Reinforcement Learning</a> 
<br><b>Andrew Wagenmaker</b>, Max Simchowitz, and Kevin Jamieson
<br><i>COLT</i>, 2022 [<a href="https://www.youtube.com/watch?v=8faG79P_QAA">Talk</a>]</p>

<p class="hidepaper"><a href="https://arxiv.org/pdf/2111.12151.pdf">Best Arm Identification with Safety Constraints</a> 
<br>Zhenlin Wang, <b>Andrew Wagenmaker</b>, and Kevin Jamieson
<br><i>AISTATS</i>, 2022</p>

<p><a href="https://arxiv.org/pdf/2102.05214.pdf">Task-Optimal Exploration in Linear Dynamical Systems</a>   
<br><b>Andrew Wagenmaker</b>, Max Simchowitz, and Kevin Jamieson
<br><i>ICML</i>, 2021 (<span class="oral">Long Talk</span>)</p>

<p class="hidepaper"><a href="https://arxiv.org/pdf/2011.00576.pdf">Experimental Design for Regret Minimization in Linear Bandits</a>  
<br><b>Andrew Wagenmaker</b>*, Julian Katz-Samuels*, and Kevin Jamieson
<br><i>AISTATS</i>, 2021</p>

<p class="hidepaper"><a href="https://arxiv.org/pdf/2002.00495.pdf">Active Learning for Identification of Linear Dynamical Systems</a>  
<br><b>Andrew Wagenmaker</b> and Kevin Jamieson
<br><i>COLT</i>, 2020 [<a href="https://www.youtube.com/watch?v=vs6zi93upfM">Talk</a>]</p>

<p class="hidepaper"><a href="https://arxiv.org/pdf/1710.08873.pdf">Robust Photometric Stereo via Dictionary Learning</a>
<br><b>Andrew Wagenmaker</b>, Brian Moore, and Raj Rao Nadakuditi
<br> <i>IEEE Transactions on Computational Imaging</i>, 2018</p>

<p class="hidepaper"><a href="https://arxiv.org/pdf/1710.00002.pdf">Robust Photometric Stereo Using Learned Image and Gradient Dictionaries</a>
<br><b>Andrew Wagenmaker</b>, Brian Moore, and Raj Rao NadakuditiÂ 
<br><i>ICIP</i>, 2017</p>

<p class="hidepaper"><a href="https://arxiv.org/pdf/1710.00230.pdf">Robust Surface Reconstruction from Gradients via Adaptive Dictionary Regularization</a>
<br><b>Andrew Wagenmaker</b>, Brian Moore, and Raj Rao Nadakuditi
<br><i>ICIP</i>, 2017</p>

<p class="hidepaper"><a href="https://web.eecs.umich.edu/~necmiye/pubs/WagenmakerO_allerton16.pdf">A Bisimulation-Like Algorithm for Abstracting Control Systems</a>
<br><b>Andrew Wagenmaker</b> and Necmiye Ozay
<br><i>Allerton</i>, 2016</p>

<p class="hidepaper"><small>* <i>equal contribution</i>, <sup>&dagger;</sup> <i>equal advising</i>, <sup>&alpha;</sup> <i>alphabetical ordering</i>, <sup>c</sup> <i>core contributor</i></small></p>


<!-- <h2 class="hidepaper">Preprints</h2> -->


<script>
  function toggleText() {
    const texts = document.querySelectorAll(".hidepaper");
    
    texts.forEach(text => {
      const currentDisplay = window.getComputedStyle(text).display;
      const button = document.getElementById("toggle");        

      if (currentDisplay === "none") {
        text.style.display = "block";
        button.innerHTML = 'All Publications (<a onclick="toggleText()">Show Selected Only</a>):';
      } else {
        text.style.display = "none";
        button.innerHTML = 'Selected Publications (<a onclick="toggleText()">Show All</a>):';
      }
    });
  }
</script>

</div>

<br>



</body>
</html>
